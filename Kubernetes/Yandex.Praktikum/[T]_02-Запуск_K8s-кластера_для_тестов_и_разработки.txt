Запуск Kubernetes кластера для тестирования и разработки

Из этого урока вы научитесь:
  -> Запускать локальный Kubernetes кластер для тестирования и разработки.
  -> Использовать сервисы облачных провайдеров для развёртывания кластеров.
  -> Настраивать конфигурацию подключения к одному или нескольким кластерам.
  -> Работать с утилитой kubectl.


Принцип работы Kubernetes на примере Sausage Store:
---
Продовый кластер:
  -> за ним будут следить выделенные админы
    <или>
  -> он будет предоставляться как услуга.

Но если возникнет потребность:
  * собрать небольшой PoC,
  * быстро протестировать разрабатываемый код
    <или>
  * пощупать саму технологию,

  => используем небольшой локальный Kubernetes кластер
---


###############################################
# Инструменты для запуска локальных кластеров # 
###############################################

********************
* 1.Docker Desktop *
********************
  ## для Windows и MacOS

  + имеет удобный пользовательский интерфейс;
  + в его конфигурации можно включить запуск Kubernetes-кластера из одной ноды.

[!] Для использования в коммерческих организациях необходима платная подписка;
    для личных целей — бесплатно.

  Для запуска кластера -> поставить галочку "Enable Kubernates" в настройках Docker Desktop


**************
* 2.Minikube *
**************
  ## нацелен на новых пользователей технологии и разработчиков приложений, работающих в Kubernetes.
  
(!) После установки minikube:
    -> самая свежая стабильная версия Kubernetes запускается одной командой:
---
minikube start
---
    -> получившийся кластер поддерживает всю основную функциональность Kubernetes:
      * локальное хранилище,
      * сеть,
      * авто-скейлинг,
      * балансировщик
      * и др. (https://github.com/kubernetes/minikube)

  Minikube — кроссплатформенный инструмент:
    = может быть запущен
      -> на Linux, 
      -> на MacOS, 
      -> Windows,

[!] Minikube может быть запущен в форме
      * виртуальной машины,
      * контейнера
        <или>
      * «железа».

[!] Для запуска Kubernetes-кластера ему нужен ДРАЙВЕР:
    > Minikube поддерживает множество драйверов;
    > для каждой ОС этот набор драйверов особенный.

-<[Например:]>-
  на Windows кластер может быть запущен в виртуальной машине
    -> на Hyper-V,
    -> на VirtualBox 
    -> на VMWare Workstation,

  в Linux кластер может быть запущен как набор контейнеров.
    + такой вариант будет производительнее и легче
      (не требует дополнительной прослойки виртуализации)

  <ещё_вариант>:
    
  в Windows:
    можно запустить кластер в контейнере — драйвер Docker,

  в Linux - в виртуальной машине — драйвер VirtualBox.

# (Актуальный список драйверов, разбитый по ОС):
# -> https://minikube.sigs.k8s.io/docs/drivers/ <-


**********
* 3.Kind *
**********
  Kind
    — это сокращение от «Kubernetes in Docker».
    Инструмент проектировался для тестирования самого Kubernetes,
    но может использоваться:
      * для локальной разработки
        <или>
      * в процессах CI.

  Кластер запускается в виде набора Docker-контейнеров
  и для него требуется:
    + работающий Docker
    + сама утилита kind (она кроссплатформенная).

[!] под капотом kind использует утилиту kubeadm
    = инструмент запуска минимально жизнеспособного кластера Kubernetes,
    предоставляемый сообществом разработчиков Kubernetes).

  Kind также СЕРТИФИЦИРОВАН Cloud Native Computing Foundation (CNCF), ➜
  ➜ значит, прошёл все тесты на совместимость,
  ➜ все запущенные на нём приложения будут работать на других сертифицированных платформах.

{сертификат соответствия: https://github.com/cncf/k8s-conformance}


**********************************
* Другие популярные дистрибутивы *
**********************************

  * k0s от Mirantis
      — полноценный дистрибутив для развёртывания кластеров, в том числе для продакшена.

  * k3s дистрибутив от Rancher
      — позиционируется как дистрибутив для минималистичных инсталляций с ограниченными ресурсами.

  * MicroK8s от Canonical (разработчики дистрибутива Ubuntu)
      — инструмент для развёртывания кластера, включая режим «высокой доступности» (high availability),
      но с минимумом усилий.
---
# Высокая доступность (high availability) в контексте Kubernetes означает,
# что кластер может выдержать сбой любого компонента и продолжить свою работу без простоя.
---


######################
# Managed Kubernetes #
######################

[!] Развёртывание и поддержка Kubernetes кластера для большой нагрузки с определённым SLA =
    = серьёзная инженерная задача.

---
SLA (Service Level Agreement)
  - это соглашение между поставщиком услуг и его клиентами,
    в котором описываются уровень сервиса и обязанности каждой стороны.

[В контексте IT-разработки:]
  SLA - это соглашение о том,
    * как будет работать приложение или сервис,
    * какие параметры будут отслеживаться для обеспечения надежности и доступности,
    * какие меры будут приняты в случае сбоя или нарушения работы.

Примеры SLA могут включать в себя:
  -> Время отклика приложения или сервиса
       (например, максимальное время, за которое должен быть обработан запрос);

  -> Доступность приложения или сервиса
       (например, минимальное количество часов в неделю или месяц, когда приложение должно быть доступно);

  -> Параметры мониторинга
       (например, какие метрики будут отслеживаться для определения надежности и производительности);

  -> Меры по восстановлению после сбоя
       (например, как быстро должна быть восстановлена работа приложения после сбоя).


  SLA может быть РАЗЛИЧНЫМ ДЛЯ РАЗНЫХ КЛИЕНТОВ или ДЛЯ РАЗНЫХ ЭТАПОВ РАЗРАБОТКИ приложения.
  Оно помогает обеим сторонам понимать ожидания и требования друг друга,
  а также обеспечивает основу для оценки качества работы и принятия мер в случае нарушений.

[В контексте Kubernetes:]
  SLA может использоваться для определения параметров мониторинга и восстановления для деплоев и приложений, работающих на Kubernetes кластере.
  Это позволяет:
    + обеспечить надежность и доступность приложений, работающих на Kubernetes;
    + гарантировать соответствие требованиям, указанным в SLA.
---

У всех крупных облачных провайдеров есть «Kubernetes-as-a-Service» (Kubernetes как сервис),
позволяющий в несколько кликов развернуть готовый к продакшену кластер
  + с автоматическим масштабированием
  + с отказоустойчивостью

  а задачи по:
    √ администрированию инфраструктуры,
    √ мониторингу доступности
    √ своевременному обновлению
=> оставить облачному провайдеру.

  "+" глубокая интеграция Kubernetes с сервисами облака.

[!]  Внутри Kubernetes запускается API-провайдер, запросы к которому транслируются в запросы к сервисам облака.
[Например:]
  -> запросы приложений на выделение дискового пространства транслируются в облако,
  -> облако создаёт необходимые диски и подключает к серверам.

(Обычно)
  -> за Сontrol Plane берётся небольшая фиксированная плата,
  -> а за worker-ноды вы платите по тарифу виртуальной машины.

В Yandex.Cloud такой сервис называется «Managed Service for Kubernetes».


##############
# Kubeconfig #
##############

  Большинство инструментов для работы с Kubernetes (например, kubectl)
  для настройки ДОСТУПА К КЛАСТЕРАМ используют файл конфигурации под названием kubeconfig.

[ расположение kubeconfig: ]
  по умолчанию:
~/.kube/config

[*] можно указать иное расположение:
    ➜ с ключом kubectl --kubeconfig <путь_к_файлу>
<или>
    ➜ хранить настройки в переменных окружения.


[ Запуск кластера с помощью minikube: ]
  При запуске кластера с помощью minikube конфигурационный файл kubeconfig СОЗДАЁТСЯ АВТОМАТИЧЕСКИ,
  и minikube сообщает об этом при помощи сообщения:

---<minikube's_message:>---
configured to use "minikube" cluster and "default" namespace by default
---


**********************
* Анализ kubeconfig: *
**********************

# Посмотрим какая информация есть в kubeconfig:

=<kubeconfig>=
---
apiVersion: v1
kind: Config

#(↓) имя текущего контекста 
current-context: kube-admin

# список контекстов
contexts:
  - name: kube-admin        # Кластер "kube" и пользователь "admin" объединены в контекст
    context: 
      cluster: kube
      user: admin
      #(↓) Пользователь admin имеет доступ к неймспейсу default
      namespace: default

# список кластеров
clusters:
  - name: kube # Кластер "kube" и его адрес
    cluster:
      server: https://192.168.49.2:8443

# Список пользователей
users:
  - name: admin
    token: 123456

##_EOF_##
---

Внутри kubeconfig используется КОНЦЕПЦИЯ КОНТЕКСТОВ:
  = контекст работы с кластером компонуется из
    + описания подключения к кластеру   и
    + конфигурации пользователя.

  Это позволяет, например, использовать одного пользователя
    -> для работы с несколькими кластерами
      <или>
    -> для работы разными неймспейсами внутри одного кластера.

*[_Namespace_]*

Namespace
    – это логическая сущность для разделения доступа в Kubernetes.
Для получения какого-либо ресурса внутри определённого неймспейса
пользователь должен иметь доступ в неймспейс,
а в командой строке можно указать соответствующий параметр:

kubectl <command> <TYPE> --namespace <имя неймспейса>.
---

В kubeconfig можно встретить различные варианты настройки аутентификации:
  * токены,
  * сертификаты
  и др.

[Сертификаты]
  -> чаще всего используются для аутентификации компонентов самого кластера
    (они тоже могут использовать kubeconfig),

[Токены]
  -> используются обычными пользователями.


****************
* Мини-резюме: *
****************
  Задачи, которые решает kubeconfig:
    + используется для хранения КОНФИГУРАЦИИ ПОДКЛЮЧЕНИЯ к Kubernetes кластеру;
    + компоненты кластера могут использовать kubeconfig для работы с его API;
    + можно держать конфигурацию подключений к разным окружениям в одном месте.


***********
* Kubectl *
***********

  Основной инструмент работы с Kubernetes API — утилита командной строки kubectl.

  Для чего используется:
    ➜ для развёртывания приложений;
    ➜ для day-2 операций.

---< Об операциях Day-2: >---
Жизненный цикл программного обеспечения можно разделить на три этапа:
  * Day-0
  * Day-1
  * Day-2

У каждого этапа свой набор действий, которые в нём выполняются:
  * Day-0
    = период времени, необходимый для того, чтобы ПРИДУМАТЬ и ЗАДОКУМЕНТИРОВАТЬ полный набор требований для кластера Kubernetes.
  (Например, понимаем, нужен ли нам Kubernetes-кластер и какая у него должна быть архитектура).

  * Day-1
    = следующий этап.
      Мы уже определились, что теперь делаем:
        - разворачиваем,
        - настраиваем,
        - тестируем,
        - говорим, что кластер готов к работе.

  * Day-2
    = всё, кластер в проде!
      √ поддерживаем его в рабочем состоянии,
      √ добавляем в кластер монторинг,
      √ заботимся о различных политиках безопасности,
      √ прикручиваем облачное хранилище
      √ и не забываем о масштабировании/обновлении/SLA самого кластера.
---


[!]  Админы кластера также запускают kubectl для управления НИЗКОУРОВНЕВЫМИ РЕСУРСАМИ, поддерживающими жизнь кластера.

Примеры некоторых команд kubectl:
---
kubectl get pods        # = вывести список подов (pods) в текущем контексте

# get — основная команда получения информации о ресурсах кластера,
# а тип ресурса так и называется pods


[Ещё пара полезных команд:]

kubectl get nodes       # покажет список нод кластера

---[OUTPUT:]---
NAME       STATUS   ROLES                  AGE   VERSION
minikube   Ready    control-plane,master   19m   v1.23.1 
---

# В Minikube стартует ОДНА НОДА, на которой запускаются все:
## control-plane (= управляющие компоненты кластера)
## Kubernetes Nodes — нода, на которой будут запускаться приложения.


  --output wide => получить расширенную информацию о нодах:
---
$ kubectl get nodes --output wide

---[OUTPUT:]---
NAME       STATUS   ROLES                  AGE   VERSION   INTERNAL-IP    EXTERNAL-IP   OS-IMAGE             KERNEL-VERSION     CONTAINER-RUNTIME
minikube   Ready    control-plane,master   19m   v1.23.1   192.168.49.2   <none>        Ubuntu 20.04.2 LTS   5.4.0-99-generic   docker://20.10.12
---

*******************************************************
* [!] kubectl может работать напрямую с API кластера: *
*******************************************************
---
$ kubectl get --raw='/readyz'

ok
---
#= Этой командой мы получили информацию о состоянии кластера с помощью «сырого» raw-запроса.
 
[!] Можно добавить подробностей в вывод, снабдив GET параметром verbose к /readyz.
[>] Это позволит увидеть, какие проверки проводились, и распознать их статус.
---
*****************************************
* $ kubectl get --raw='/readyz?verbose' *
*****************************************
#[OUTPUT:]

[+]ping ok
[+]log ok
[+]etcd ok
[+]informer-sync ok
[+]poststarthook/start-kube-apiserver-admission-initializer ok
[+]poststarthook/generic-apiserver-start-informers ok
[+]poststarthook/priority-and-fairness-config-consumer ok
[+]poststarthook/priority-and-fairness-filter ok
[+]poststarthook/start-apiextensions-informers ok
[+]poststarthook/start-apiextensions-controllers ok
[+]poststarthook/crd-informer-synced ok
[+]poststarthook/bootstrap-controller ok
[+]poststarthook/rbac/bootstrap-roles ok
[+]poststarthook/scheduling/bootstrap-system-priority-classes ok
[+]poststarthook/priority-and-fairness-config-producer ok
[+]poststarthook/start-cluster-authentication-info-controller ok
[+]poststarthook/aggregator-reload-proxy-client-cert ok
[+]poststarthook/start-kube-aggregator-informers ok
[+]poststarthook/apiservice-registration-controller ok
[+]poststarthook/apiservice-status-available-controller ok
[+]poststarthook/kube-apiserver-autoregistration ok
[+]autoregister-completion ok
[+]poststarthook/apiservice-openapi-controller ok
[+]shutdown ok
readyz check passed
---


<?>_Почему бы сразу не использовать K8s + Minikube?_<?>

  Minikube специально предоставляет ТОЛЬКО "ВЕРХУШКУ АЙСБЕРГА",
  -> дабы мы не отвлекались на неё в процессе ТЕСТИРОВАНИЯ.

  Реальный же Production-кластер относится как раз к "подводной части",
  и с ней нам ещё предстоит работать
---

---< More commands >---
kubectl get services                          # Вывести все сервисы в пространстве имён
kubectl get pods --all-namespaces             # Вывести все поды во всех пространств имён
kubectl get pods -o wide                      # Вывести все поды в текущем пространстве имён с подробностями
kubectl get deployment my-dep                 # Вывести определённое развёртывание
kubectl get pods                              # Вывести все поды в пространстве имён
kubectl get pod my-pod -o yaml                # Получить информацию по поду в формате YAML

# Посмотреть дополнительные сведения команды с многословным выводом
kubectl describe nodes <my-node>
kubectl describe pods <my-pod>

# Вывести сервисы, отсортированные по имени
kubectl get services --sort-by=.metadata.name

# Вывести поды, отсортированные по количеству перезагрузок
kubectl get pods --sort-by='.status.containerStatuses[0].restartCount'

# Вывести постоянные тома (PersistentVolumes), отсортированные по емкости
kubectl get pv --sort-by=.spec.capacity.storage

# Получить метку версии всех подов с меткой app=cassandra
kubectl get pods --selector=app=cassandra -o \
  jsonpath='{.items[*].metadata.labels.version}'

# Получить все рабочие узлы (с помощью селектора исключаем узлы с меткой 'node-role.kubernetes.io/master')
kubectl get node --selector='!node-role.kubernetes.io/master'

# Получить все запущенные поды в пространстве имён
kubectl get pods --field-selector=status.phase=Running

# Получить внешние IP-адреса (ExternalIP) всех узлов
kubectl get nodes -o jsonpath='{.items[*].status.addresses[?(@.type=="ExternalIP")].address}'

# Вывести имена подов, принадлежащие к определённому RC
# Использование команды "jq" помогает упросить поиск в jsonpath, подробнее смотрите на сайте https://stedolan.github.io/jq/
sel=${$(kubectl get rc my-rc --output=json | jq -j '.spec.selector | to_entries | .[] | "\(.key)=\(.value),"')%?}
echo $(kubectl get pods --selector=$sel --output=jsonpath={.items..metadata.name})

# Показать метки всех подов (или любого другого объекта Kubernetes, которым можно прикреплять метки)
kubectl get pods --show-labels
---
(взято с https://kubernetes.io/ru/docs/reference/kubectl/cheatsheet/)


************************
* Ключевые мысли урока *
************************

  (!) Существуют несколько простых способов запустить тестовый Kubernetes кластер на локальной машине.
  (!) Minikube — простой инструмент для запуска Kubernetes кластера,
      который ориентируется на новых пользователей и разработчиков приложений.
  (!) kubeconfig — конфигурационный файл, описывающий подключение к одному или нескольким кластерам.
  (!) kubectl — основной инструмент работы с Kubernetes кластером.
      Им пользуются как админы, так и пользователи-разработчики.


**********************
* Полезные материалы *
**********************

Minikube:
  https://minikube.sigs.k8s.io/docs/

Kind:
  https://kind.sigs.k8s.io/

Документация по kubeconfig:
  https://kubernetes.io/docs/concepts/configuration/organize-cluster-access-kubeconfig/

Обзор kubectl:
  https://kubernetes.io/ru/docs/reference/kubectl/overview/

Обзор инструментов запуска тестового кластера Kubernetes:
  https://habr.com/ru/companies/flant/articles/572188/

Yandex Cloud Managed Kubernetes:
  https://yandex.cloud/ru/docs/managed-kubernetes/?utm_referrer=https%3A%2F%2Fpracticum.yandex.ru%2F

---{ sources: }---
"Документация по Kubernetes": https://kubernetes.io/ru/docs/home/
"Записки DevOps. Шпаргалка по Kubernetes": https://devops.org.ru/kubernetes-summary
to_read:
"10 лет Kubernetes: как родился один из самых крупных Open Source-проектов современности":
-> https://habr.com/ru/companies/flant/articles/820153/

"The History of Kubernetes & the Community Behind It":
-> https://kubernetes.io/blog/2018/07/20/the-history-of-kubernetes-the-community-behind-it/

*{ "Wasm vs Docker containers vs Kubernetes vs serverless: битва за первенство"
   https://habr.com/ru/companies/flant/articles/796857/
}
---

* Создатели Kubernetes: *
Крейг Маклаки,
Джо Беда,
Брендан Бёрнс
++ разработчики:
Вилле Айкас,
Тим Хокин,
Доун Чен,
Брайан Грант
Дэниел Смит

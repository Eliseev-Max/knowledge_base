Логирование

Из этого урока вы научитесь:
  ● Базовым способам просмотра логов через консоль Linux
  ● Делать выводы по результатам просмотра логов
  ● Логировать приложение Java и nodejs:
      - хранение в Json;
      - отправка в stdout, а не в файл,
        (stdout подхватывается Docker'ом)
  ● Централизованно собирать логи в Kubernetes
  ● Разбираться в различных способах сбора логов


# Просмотр логов в системном журнале:
$ sudo journalctl -u sausage-store.service

## Системный журнал
## = логи, в которые система записывает информацию о том, что в ней происходит
## (действия пользователей, работа приложений);
## + эти логи — основной источник информации о событиях в системе, в том числе и об ошибках.

(!) Приложения могут писать логи не только в системный журнал,
    но и в собственную директорию — хорошим тоном считается
/var/log/<service_name>

  Это удобно, так как всегда знаешь, где искать логи по умолчанию.


*************
* logrotate *
*************

--< logrotate-config >--
/var/log/duchess-pear-store.log {
  rotate 12             # максимальное количество файлов хранения
  monthly               # годовой, месячный, недельный, дневной, часовой
  compress              # архивирование и сжатие
  delaycompress         # последний и предпоследний файл не будут заархивированы
  missingok             # если файла лога нет, то не будет и нотификации об ошибке
  size 100M             # размер лога, после которого он будет ротирован
  dateext               # добавит дату ротации перед заголовком старого лога
  create                # создаст пустой файл после того, как старый будет ротирован
  postrotate            # выполнит после ротации какой-нибудь скрипт
    <путь к скрипту или команда>
  endscript
}
<--

[Логи контейнеров Docker]

docker logs <имя контейнера> [-f]
  -f = логи будут показываться в режиме реального времени

Можно посмотреть логи в файле контейнера.
Контейнеры имеют свои директории на хостовой машине и пишут в неё логи и другую информацию.
Обычно директория контейнеров распологается по адресу:

/var/lib/docker/containers/<container_id>

[!] Можно указать Docker'у, что делать с логами из контейнера;
# например, пересылать в определённое место.

Делается это в файле, который настраивает `docker daemon`:
# cat /etc/docker/daemon.json

--< /etc/docker/daemon.json >--
{
    "dns-search": ["."],
    "storage-driver": "overlay2",
    "storage-opts": ["overlay2.override_kernel_check=1"],
    "labels": [],
    "live-restore": true,
    "log-driver": "gelf",
    "log-opts": {
        "gelf-address": "udp://localhost:12201",
        "gelf-compression-type": "none"
    },
    .....
}
##END##

# В данном примере логи просто отправляются в gelf-сервис, который поднят на порту 12201

# Если логи перенаправить в другой сервис, не поддерживающий чтение логогв, то при вызове $ docker logs <container-id> получим:
---
Error response from daemon: configured logging driver does not support reading
---


********
* GELF *
********

GELF (Graylog Extended Format logging driver)
  = формат записи логов, с которым умеют работать многие инструменты,
    например, Graylog, Logstash и Fluentd.

  В GELF каждое сообщение журнала представляет собой СЛОВАРЬ со следующими полями:
  ● версия
  ● хост (кто отправил сообщение)
  ● timestamp
  ● короткая и полная версия сообщения
  ● любые настраиваемые поля, которые вы редактируете самостоятельно


(?) Как Докер понимает, откуда отображать логи приложения при использовании утилиты docker logs?
(>) Приложение должно писать свои логи на stdout

-->
$ kubectl logs sausage-store
Can't detect user region: file 'regions.db' corrupted!
<--

[Форматы хранения логов:]
  Строка:
    будет удобна, если смотришь логи в консоли и грепаешь нужную информацию.


#(!) существует два понятия: структурированные и неструктурированные логи.
# Разберёмся на примере лога Nginx:

1) в неструктурированном виде:
-->
92.34.63.77 - - [26/Jun/2016:14:06:22 -0400] "GET / HTTP/1.1" 301 184
"-" "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,
like Gecko) Chrome/47.0.2526.111 (StatusCake)" "-"
<--

2) в структурированном виде:
-->
{
  "remote_addr": "192.34.63.77",
  "remote_user": "-",
  "time": "2016-06-26T14:06:22-04:00",
  "request": "GET / HTTP/1.1",
  "status": "301",
  "body_bytes_sent": "184",
  "http_referrer": "-",
  "http_user_agent": "Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML,  like  Gecko)  Chrome/47.0.2526.111 (StatusCake)",
  "http_x_forwarded_for": "-"
}
<--

(?) как заставить Докер складировать логи в json? 
(!) на первых парах можно явно сказать Докеру, в каком формате логи писать:

#[ГЛОБАЛЬНО:]
--< /etc/docker/daemon.json: >--
{
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "10m",
    "max-file": "3"
  }
}
---
# Тогда все контейнеры под управлением докер-демона будут писать логи в json-формате.

#[ЛОКАЛЬНО:]
(!) Также можно при запуске контейнера указать:
[docker run:]    docker run -it --log-driver json-file --log-opt max-size=10m --log-opt max-file=3 sausage-backend

[docker compose:]
--<docker-compose.yaml>--
version: '3.8'
services:
  sausage-backend:
    image: <repository address>/sausage-backend:<version>
    ports:
      - "80:8080"
    logging:
      driver: "json-file"
      options:
        max-size: 10m
        max-file: "3"
...


<?>- В чём может быть проблема? -<?>

  Docker не всесильный и порой некорректно парсит стектрейс от приложения.
    -> иногда склеивает в одну строку,
    -> а иногда просто кидает кучу строк
  и придётся попотеть, чтобы отследить весь стектрейс.
  Что он в принципе делает, так это кладёт строку лога в одно поле.


[Какие бывают логи:]
  INFO
  WARN
  DEBUG
  ERROR
  TRACE


(?) Задание 7
  Пришёл http-запрос в приложение, в нём есть пачка заголовков:
--[Request]--
Referer: /
Authorization: OAuth fdsjs;y6fgh35ufnkcuabyuv2
User-Agent: curl/7.77.0
Username: vasya
Content-type: text/html; charset=utf-8
X-Forwarded-for: 192.168.1.1 
--##--

Какой заголовок не будем логировать?

(!) Authorization, потому что содержит авторизационную информацию


Работу с логами можно разбить на несколько этапов:
  1) Сбор логов с серверов и контейнеров с помощью агентов или клиентских библиотек
     и их отправка по сетевым протоколам в централизованное хранилище
       -> либо напрямую,
       -> либо через агрегаторы с предварительной обработкой;

  2) Обработка логов.
     Внутри агрегаторов лог-сообщения
       ✓ парсятся,
       ✓ обогащаются дополнительной информацией
         (отметкой времени, идентификатором источника, меткой местоположения и т.п.),
       ✓ приводятся к единому формату   и
       ✓ отправляются в хранилище в виде готовых для индексирования полей и их значений;

  3) Хранение логов и управление хранилищем;

  4) Анализ и визуализация данных, полученных из логов


"Хранилки" логов:
  ● ELK-стек (Elasticsearch + Logstash + Kibana)
  ● Graylog
  ● Loki (Promtail + Loki + Grafana)


#######
# ELK #
#######

Существуют различные агенты для сбора логов, которые могут отправлять их НАПРЯМУЮ
  -> в Elasticsearch
    или
  -> в Logstash.

Logstash — это такой агрегатор логов, который нужен для их предварительной обработки.

После того как логи были обработаны, Logstash отправляет их в NoSQL-базу Elasticsearch.

Logstash богат на плагины для подобных операций (grok, date, geoip, multiline и другие),
которые позволяют
  ✓ преобразовать логи,
  ✓ добавить в них различную информацию,
  ✓ парсить поля
  и т.д.

Logstash слегка грузный => альтернатива:
   * FluentD (написан на Ruby)
   * FluentBit (на базе Go)


Kibana
  -> занимается просмотром логов, метрик и трасс.

  = это очень мощный инструмент, отличающийся нетривиальной настройкой.

Кибана ~ "окошко" в Elasticsearch:
  она подключается к Elasticsearch и отображает логи.

Elasticsearch — это не просто база, но и ещё очень мощный ПОИСКОВЫЙ ДВИЖОК,

=> если нужен глубокий релевантный поиск по логам и нетривиальтная аналитика — Elasticsearch = очень подходящий инструмент.


###########
# Graylog #
###########

  Graylog предоставляет:
    ✓ удобный UI 
    ✓ более простой в настройке, чем ELK,
    - под капотом он использует Elasticsearch более старой версии для хранения логов
      и MongoDB для хранения конфигов.

#=> Неплохой вариант для первой системы логирования.

  Агрегатор логов            |
    <и>                      |> прикручены прямо к Graylog и не идут отдельными компонентами.
  плагины по обработке логов | 

УДОБНО:
  + преобразовывать логи 
  + комбинировать их между собой,
  #+ а чуть позже Graylog вообще разжился механизмом коллекторов логов Graylog Collector Sidecars.


########
# Loki #
########

Состоит из:
  * Promtail
    = сборщик и обработчик логов

  * Loki
    = хранилище логов

  * Grafana
    = для визуализаций.

[!] Loki индексирует ТОЛЬКО МЕТАДАННЫЕ, а не весь лог, как Elasticsearch
    + прилично экономит расходы
    - снижает возможность анализа логов.

  В отличие от Elasticsearch, Loki не снабжён полнотекстовым поиском:
    данные сначала ищутся по индексированным полям,
    а затем грепаются по регулярным выражениям.

(!) По скорости и экономии ресурсов Loki гораздо привлекательней Elasticsearch. 

  Если Elasticsearch используется только для хранения логов и простого поиска —> это лишь 10% его возможностей

# то есть вы гоняете целый железнодорожный состав для доставки пары коробок апельсинов.

Зачастую для простого поиска по логам таких мощностей не требуется.


Задание 8
Перетяните сервисы на правильную операцию:

[Отправка логов в хранилище:]
  Promtail
  Logstash
  Graylog Collector Sidecars

[Хранение логов:]
  ElasticSearch
  Loki

[Отображение логов из хранилища:]
  Graylog (кусочек)
  Grafana
  Kibana


########################
# Ключевые мысли урока #
########################

  Логи — это здорово, классно, полезно.
  Идея логов одна на всех, неважно, используете ли вы приложение, развёрнутое на железе, в контейнере или в Кубере.
  Логи можно писать локально, но удобнее в удалённую хранилку.
  Существует много различных распределённых хранилок для логов: Elasticsearch, Loki, Graylog.

######################
# Полезные материалы #
######################

"Practical Monitoring — Mike Julian"

"Хабр: ELK vs Graylog vs Grafana Loki vs Monq": https://habr.com/ru/articles/594805/

"DevOps measurement: Monitoring and observability": 
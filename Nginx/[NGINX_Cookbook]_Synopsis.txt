Chapter 2
"High-Performance Load Balancing"
2.0 Introduction

"Today’s internet user experience demands performance and uptime."

Сегодняшние пользователи Интернета требуют производительности и безотказной работы.
Для этого запускается несколько копий одной и той же системы, и нагрузка распределяется между ними.
По мере увеличения нагрузки можно подключить еще одну копию системы.

Этот архитектурный прием называется горизонтальным масштабированием (horizontal scaling).
Инфраструктура на базе программного обеспечения становится все более популярной благодаря своей гибкости, открывающей огромный мир возможностей.
Независимо от того, какова цель использования инфраструктуры
  - небольшая, как два сервера для обеспечения высокой доступности, 
  - или большая, как тысячи по всему миру,
  необходимо решение для балансировки нагрузки, которое будет таким же динамичным, как и инфраструктура.

NGINX удовлетворяет эту потребность несколькими способами, такими как Балансировка нагрузки
  * HTTP,
  * TCP 
  * и протокола пользовательских дейтаграмм (UDP),
о которой мы расскажем в этой главе.

При балансировке нагрузки важно, чтобы воздействие на клиентский опыт было полностью положительным.
Во многих современных веб-архитектурах используются уровни приложений без статистики, хранящие состояние в общей памяти или базах данных.
Однако это реальность не для всех. Состояние сеанса имеет огромную ценность и значение в интерактивных приложениях.
Это состояние может храниться локально на сервере приложения по ряду причин; 
  например, в приложениях, для которых обрабатываемые данные настолько велики,
  что сетевые накладные расходы слишком дороги с точки зрения производительности.

Когда состояние хранится локально на сервере приложений, для удобства пользователей очень важно,
чтобы последующие запросы продолжали доставляться на тот же сервер.
Другая сторона ситуации заключается в том, что серверы не должны освобождаться до завершения сессии.

Для масштабной работы с приложениями с изменяемым состоянием требуется интеллектуальный балансировщик нагрузки.
NGINX Plus предлагает несколько способов решения этой проблемы с помощью отслеживания файлов cookie или маршрутизации.

В этой главе мы рассмотрим сохранение сеансов в контексте балансировки нагрузки с помощью NGINX и NGINX Plus.


---{стр.10 (28): 2.0 Introduction}---
Важно убедиться, что приложение, которое обслуживает NGINX, здорово.
По ряду причин восходящие запросы (upstream requests) могут начать отказывать.
Это может быть связано с подключением к сети, отказом сервера или приложения.
Прокси-серверы и балансировщики нагрузки должны быть достаточно умными,
чтобы обнаружить отказ вышестоящих серверов (upstream servers)
(серверов расположенных за балансировщиком нагрузки или прокси-сервером) и прекращать передачу трафика на них;
в противном случае клиент будет ждать, а в ответ получит тайм-аут.

Способ уменьшить снижение качества обслуживания при отказе сервера заключается в том, чтобы прокси проверял работоспособность вышестоящих серверов.
NGINX предлагает два различных типа проверки работоспособности (health checks):
  * пассивную, доступную в версии с открытым исходным кодом,
  * и активную, доступную только в NGINX Plus.

Активные проверки здоровья (Active health checks):
  1) через регулярные промежутки времени устанавливают соединение или запрос к вышестоящему серверу
  2) и проверяют правильность ответа.

Пассивные проверки здоровья (Passive health checks) отслеживают подключение или ответы вышестоящего сервера по мере того,
как клиенты выполняют запрос или подключение.

Вы можете использовать пассивные проверки работоспособности для снижения нагрузки на вышестоящие серверы,
а активные проверки работоспособности - для определения отказа вышестоящего сервера до того, как клиент получит отказ.

В конце этой главы мы рассмотрим мониторинг работоспособности серверов приложений, для которых выполняется балансировка нагрузки.

---

Задача: Вам нужно распределить нагрузку между двумя или более HTTP-серверами.
Решение: Используйте HTTP-модуль NGINX для балансировки нагрузки на HTTP-серверы, используя блок upstream:

-->
upstream backend {
    server 10.10.12.45:80      weight=1;
    server app.example.com:80  weight=2;
    server spare.example.com:80  backup;
}
server {
    location / {
        proxy_pass http://backend;
    }
}
<--

/*---{стр. 11 (29): Discussion}---

Модуль HTTP upstream управляет балансировкой нагрузки для HTTP.
Этот модуль определяет пул destinations (серверов назначения) = любую комбинацию сокетов Unix, IP-адресов и записей DNS или их сочетание.

Модуль upstream также определяет, как любой отдельный запрос будет назначен любому из серверов upstream.
Каждый (вышестоящий сервер назначения) upstream destination определяется в пуле upstream директивой server.

Директива server представляет собой:
  => сокет Unix || IP-адрес || полное доменное имя (FQDN)
     + а также ряд необязательных параметров.

Дополнительные параметры дают больше возможностей для контроля над маршрутизацией запросов.
Эти параметры включают
  weight = вес сервера в алгоритме балансировки,
  режим ожидания, доступность или недоступность сервера (standby mode || available || unavailable),
  а также способ определения недоступности сервера.

NGINX Plus предоставляет ряд других удобных параметров, таких как
  лимиты подключений к серверу,
  расширенный контроль разрешения DNS
  и возможность медленно наращивать количество подключений к серверу после его запуска.

---*/
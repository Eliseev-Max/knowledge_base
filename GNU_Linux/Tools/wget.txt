Утилита wget:
	* предназначена для скачивания файлов и интернет-страниц.
	* работает с протоколами:
		• HTTP
		• HTTPS
		• FTP
	
	* поддерживается работа через прокси
	* может выполнять загрузку файлов в фоновом режиме, без участия пользователя
	* реализует рекурсивную загрузку (функция открытия ссылок на страницы → сохранение целых сайтов)

Синтаксис:
	$ wget [опции] URL [URL2 URL3]
	
Опции:
	• опции можно записывать как до URL, так и после
	• между опцией и её значением не обязательно ставить пробел ( -o log == -olog)
	• если у опции нет параметров (флаги), не обязательно начинать каждую с "-"
	  (-drc == -d -r -c)
	
	Основные опции:
	-V (--version) - вывести версию программы
    -h (--help) - вывести справку
    -b (--background) - работать в фоновом режиме
    -o файл (--out-file) - указать лог файл
    -d (--debug) - включить режим отладки
    -v (--verbose) - выводить максимум информации о работе утилиты
    -q (--quiet) - выводить минимум информации о работе
    -i файл (--input-file) - прочитать URL из файла
    --force-html - читать файл указанный в предыдущем параметре как html
    -t (--tries) - количество попыток подключения к серверу
    -O файл (--output-document) - файл в который будут сохранены полученные данные
    -с (--continue) - продолжить ранее прерванную загрузку
    -S (--server-response) - вывести ответ сервера
    --spider - проверить работоспособность URL
    -T время (--timeout) - таймаут подключения к серверу
    --limit-rate - ограничить скорость загрузки
    -w (--wait) - интервал между запросами
    -Q (--quota) - максимальный размер загрузки
    -4 (--inet4only) - использовать протокол ipv4
    -6 (--inet6only) - использовать протокол ipv6
    -U (--user-agent)- строка USER AGENT отправляемая серверу
    -r (--recursive)- рекурсивная работа утилиты
    -l (--level) - глубина при рекурсивном сканировании
    -k (--convert-links) - конвертировать ссылки в локальные при загрузке страниц
    -P (--directory-prefix) - каталог, в который будут загружаться файлы
    -m (--mirror) - скачать сайт на локальную машину
    -p (--page-requisites) - во время загрузки сайта скачивать все необходимые ресурсы

Использование wget
	(Установка:
		$ sudo apt install wget
		$ yum -y install wget)
	
	Загрузка файла:
		$ wget <URL_файла>
	# wget linux скачает один файл и сохранит его в текущей директории
	# Во время загрузки увидим:
	#	• прогресс загрузки;
	#	• размер файла
	#	• дату последнего изменения файла
	#	• скорость загрузки

---
[sources:
0. https://www.gnu.org/software/wget/manual/wget.html
1. https://losst.pro/komanda-wget-linux
2. https://habr.com/ru/company/ruvds/blog/346640/
]